# ğŸ“„ RAG Document Q&A with Query Expansion, RRF Hybrid Reranking & Session Memory

An end-to-end **Retrieval-Augmented Generation (RAG)** system built with:
- **LangChain**
- **Ollama LLMs + Embeddings**
- **Chroma Vector DB (persistent storage)**
- **Cross-Encoder + BM25 hybrid reranker (RRF)**
- **Multi-query expansion** for better recall
- **Session memory (chat history)** to keep context across turns
- **Streamlit UI** for interactive Q&A

---

## âœ¨ Features
âœ… Upload any **PDF document**  
âœ… Automatic **text extraction, cleaning, and chunking**  
âœ… **Persistent ChromaDB collections** (no repeated embedding on reload)  
âœ… **Multi-query expansion** â†’ improves recall  
âœ… **Hybrid Reranking (RRF)** â†’ combines **Cross-Encoder (dense)** + **BM25 (sparse)** for better results  
âœ… **RunnableWithMessageHistory memory** â†’ remembers your conversation in-session  
âœ… Simple & clean **Streamlit UI** with expansions, top chunks, and final grounded answer  

---

## ğŸ—ï¸ Architecture Flow

```

```
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   PDF File  â”‚
     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
            â”‚ Extract
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Preprocessingâ”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ Chunk + Embed
           â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Persistent Chroma â”‚
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Query Input â”‚
   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Expand queries (LLM)
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Multi-Retrieverâ”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ Collect candidates
           â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ RRF Hybrid Rerank â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ Top chunks
          â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Ollama LLM (Context) â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Final Answer â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

````

---

## ğŸ›ï¸ Usage

1. **Upload a PDF** â†’ text will be extracted, cleaned, chunked, and embedded.

   * Collection is persisted in `./db` (named after the file).
   * On re-upload, system **reuses embeddings** (no repeated computation).

2. **Ask a Question** â†’

   * System will generate paraphrases of your query.
   * Retrieve chunks with Chroma (dense), expand recall with BM25, then rerank via **RRF (Cross-Encoder + BM25)**.
   * Answer strictly from context.

3. **Conversation Memory** â†’

   * System remembers your previous questions & answers in the current session.
   * Youâ€™ll see the **chat history** at the bottom.
