# ğŸ“„ RAG Document Q&A with Query Expansion, RRF Hybrid Reranking & Session Memory

An end-to-end **Retrieval-Augmented Generation (RAG)** system built with:
- **LangChain**
- **Ollama LLMs + Embeddings**
- **Chroma Vector DB (persistent storage)**
- **Cross-Encoder + BM25 hybrid reranker (RRF)**
- **Multi-query expansion** for better recall
- **Session memory (chat history)** to keep context across turns
- **Streamlit UI** for interactive Q&A

---

## âœ¨ Features
âœ… Upload any **PDF document**  
âœ… Automatic **text extraction, cleaning, and chunking**  
âœ… **Persistent ChromaDB collections** (no repeated embedding on reload)  
âœ… **Multi-query expansion** â†’ improves recall  
âœ… **Hybrid Reranking (RRF)** â†’ combines **Cross-Encoder (dense)** + **BM25 (sparse)** for better results  
âœ… **RunnableWithMessageHistory memory** â†’ remembers your conversation in-session  
âœ… Simple & clean **Streamlit UI** with expansions, top chunks, and final grounded answer  

---

## ğŸ—ï¸ Architecture Flow

PDF File --> Preprocessing --> Persistent Chroma --> Query Input --> Query Expansion --> Multi-Retriever --> RRF Hybrid Rerank --> LLM --> Final Response


---

## ğŸ›ï¸ Usage

1. **Upload a PDF** â†’ text will be extracted, cleaned, chunked, and embedded.

   * Collection is persisted in `./db` (named after the file).
   * On re-upload, system **reuses embeddings** (no repeated computation).

2. **Ask a Question** â†’

   * System will generate paraphrases of your query.
   * Retrieve chunks with Chroma (dense), expand recall with BM25, then rerank via **RRF (Cross-Encoder + BM25)**.
   * Answer strictly from context.

3. **Conversation Memory** â†’

   * System remembers your previous questions & answers in the current session.
   * Youâ€™ll see the **chat history** at the bottom.
